# LSTM Attack Prediction Model

## Model Architecture

The attack prediction component uses a Long Short-Term Memory (LSTM) network to predict the next actions of an attacker based on observed attack patterns. This allows the defense system to anticipate attacks before they occur, enabling proactive defense.

### LSTM Network Structure

The LSTM model is implemented in `models/attack_predictor.py` with the following architecture:

```
Embedding Layer (227 → config.LSTM_EMBEDDING_SIZE)
    ↓
Bidirectional LSTM Layer 1 (embedding_size → hidden_units[0]*2)
    ↓
Bidirectional LSTM Layer 2 (hidden_units[0]*2 → hidden_units[1]*2)
    ↓
Dropout Layer (rate=0.5)
    ↓
Fully Connected Layer (hidden_units[1]*2 → output_classes)
```

### Neural Network Implementation

```python
class LSTMAttackPredictor(nn.Module):
    def __init__(self, config, seq_length=10):
        super(LSTMAttackPredictor, self).__init__()
        self.config = config
        self.seq_length = seq_length
        
        # Embedding layer
        self.embedding = nn.Embedding(
            num_embeddings=227,  # 227 different event occurrences
            embedding_dim=config.LSTM_EMBEDDING_SIZE
        )
        
        # Bidirectional LSTM layers
        self.lstm1 = nn.LSTM(
            input_size=config.LSTM_EMBEDDING_SIZE,
            hidden_size=config.LSTM_HIDDEN_UNITS[0],
            bidirectional=True,
            batch_first=True
        )
        
        self.lstm2 = nn.LSTM(
            input_size=config.LSTM_HIDDEN_UNITS[0]*2,  # *2 for bidirectional
            hidden_size=config.LSTM_HIDDEN_UNITS[1],
            bidirectional=True,
            batch_first=True
        )
        
        # Dropout for regularization
        self.dropout = nn.Dropout(0.5)
        
        # Fully connected output layer
        self.fc = nn.Linear(
            in_features=config.LSTM_HIDDEN_UNITS[1]*2,  # *2 for bidirectional
            out_features=config.LSTM_OUTPUT_CLASSES
        )
```

## Mathematical Foundation

### LSTM Cell

Each LSTM cell processes sequence elements with the following operations:

1. **Forget Gate** - Determines what information to discard from cell state:
   $$f_t = \sigma(W_f \cdot [h_{t-1}, x_t] + b_f)$$

2. **Input Gate** - Determines what new information to store in cell state:
   $$i_t = \sigma(W_i \cdot [h_{t-1}, x_t] + b_i)$$
   $$\tilde{C}_t = \tanh(W_C \cdot [h_{t-1}, x_t] + b_C)$$

3. **Cell State Update** - Updates the cell state:
   $$C_t = f_t * C_{t-1} + i_t * \tilde{C}_t$$

4. **Output Gate** - Determines what to output based on cell state:
   $$o_t = \sigma(W_o \cdot [h_{t-1}, x_t] + b_o)$$
   $$h_t = o_t * \tanh(C_t)$$

Where:
- $\sigma$ is the sigmoid function
- $[h_{t-1}, x_t]$ is the concatenation of the previous hidden state and current input
- $W$ and $b$ are weight matrices and bias vectors
- $*$ denotes element-wise multiplication

### Bidirectional Architecture

The bidirectional LSTM processes the sequence in both forward and backward directions:

$$\overrightarrow{h}_t = \text{LSTM}_{\text{forward}}(x_t, \overrightarrow{h}_{t-1})$$
$$\overleftarrow{h}_t = \text{LSTM}_{\text{backward}}(x_t, \overleftarrow{h}_{t+1})$$
$$h_t = [\overrightarrow{h}_t, \overleftarrow{h}_t]$$

This allows the model to capture dependencies from both past and future contexts in the sequence.

## Training Process

### Data Generation

The training data is generated by the `RealisticAttackDataGenerator` class in `utils/data_generator.py`:

```python
def generate_batch(self, batch_size, seq_length):
    X = np.zeros((batch_size, seq_length, self.num_states))
    y = np.zeros((batch_size, seq_length, self.num_states))
    
    for i in range(batch_size):
        # Create a random attack sequence following realistic patterns
        attack_sequence = self._generate_attack_sequence(seq_length)
        
        # Convert to one-hot encoding for X
        for j, attack in enumerate(attack_sequence[:-1]):
            X[i, j, attack] = 1
            
        # Set the targets (next attack in sequence)
        for j, attack in enumerate(attack_sequence[1:]):
            y[i, j, attack] = 1
            
        # Add the last prediction target
        last_attack = self._predict_next_attack(attack_sequence)
        y[i, -1, last_attack] = 1
    
    return X, y
```

### Training Loop

The LSTM model is trained with:

1. **Optimizer**: Adam with learning rate 1e-4 and L2 regularization (weight decay 1e-4)
2. **Loss Function**: Cross-entropy loss for classification
3. **Gradient Clipping**: Applied to prevent exploding gradients
4. **Train-Validation Split**: 80% training, 20% validation
5. **Regularization**: Dropout with rate 0.5 to prevent overfitting

The training process is as follows:

```python
for epoch in range(epochs):
    # Training phase
    lstm_model.train()
    running_loss = 0.0
    correct = 0
    total = 0
    
    for inputs, labels in train_loader:
        lstm_model.optimizer.zero_grad()
        outputs = lstm_model(inputs)
        loss = lstm_model.criterion(outputs, labels)
        loss.backward()
        
        # Apply gradient clipping
        torch.nn.utils.clip_grad_norm_(lstm_model.parameters(), config.LSTM_GRADIENT_CLIP_NORM)
        
        lstm_model.optimizer.step()
        
        # Tracking metrics
        running_loss += loss.item()
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()
    
    # Calculate epoch metrics
    train_loss = running_loss / len(train_loader)
    train_acc = correct / total
    
    # Validation phase
    # ... (similar process without gradient updates)
```

## Inference Process

During operation, the LSTM model predicts the next attack based on a sequence of previous attacks:

```python
def predict_attack_sequence(self, initial_event, max_length=10):
    """Predict an attack sequence starting from an initial event"""
    self.eval()
    current_event = initial_event
    sequence = [current_event]
    
    with torch.no_grad():
        for _ in range(max_length - 1):
            # Pad sequence if needed
            padded_sequence = sequence.copy()
            while len(padded_sequence) < self.seq_length:
                padded_sequence = [0] + padded_sequence
            
            # Take only the last seq_length elements if too long
            if len(padded_sequence) > self.seq_length:
                padded_sequence = padded_sequence[-self.seq_length:]
            
            # Make prediction
            input_tensor = torch.LongTensor([padded_sequence])
            output = self(input_tensor)
            next_event = int(torch.argmax(output, dim=1).item())
            
            # Stop if predicting the same event
            if next_event == current_event:
                break
            
            sequence.append(next_event)
            current_event = next_event
    
    return sequence
```

## Performance Metrics

The LSTM model's performance is evaluated using:

1. **Validation Accuracy**: Percentage of correctly predicted next attack steps
2. **Validation Loss**: Cross-entropy loss on the validation set
3. **Prediction Horizon**: How many steps ahead the model can accurately predict

Typical performance metrics from the latest run:
- Training Accuracy: 96.80%
- Validation Accuracy: 95.50%
- Training Loss: 0.11
- Validation Loss: 0.14

These metrics indicate a well-trained model that can effectively predict attack sequences without overfitting to the training data.