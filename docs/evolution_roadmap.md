# Project Evolution Roadmap

## 1. Objective
To evolve the RL-IoT Defense System by integrating real-world data from the CICIoT2023 dataset with synthetic data generated by a Generative Adversarial Network (GAN). This roadmap will guide the development of a more robust, adaptive, and realistic defense agent, directly aligning with the Master's thesis objectives.

## Phase 1: Real Data Integration (CICIoT2023)
This is the foundational phase, focused on adapting the system to work with a real-world, standard dataset.

### 1.1. Data Exploration & Preprocessing
- **Action:** Acquire the CICIoT2023 dataset.
- **Task:**
    - Perform a thorough exploratory data analysis (EDA).
    - Analyze the features to understand their types, ranges, and distributions.
    - Document the class distribution to understand the imbalance between benign and attack traffic.

### 1.2. Environment Adaptation
- **Action:** Update the `IoTEnv` class (`src/environment.py`) to handle real data & synthetic data as well.
- **Action:** Upgrade the environment to reflect a more realistic IoT network, including:
    - **State Representation:** Use the features from the CICIoT2023 dataset to represent the state of the IoT network.
    - **Action Space:** Define actions that correspond to real-world defensive measures (e.g., block, quarantine, monitor).

### 1.3. Redefine the Reward Function
- **Action:** Update the reward logic within `IoTEnv` for the dataset mode.
- **Task:** The reward should now be based on the agent's classification performance against the dataset's ground-truth labels.
- **Example Logic:**
    - High positive reward for correctly blocking a labeled Attack.
    - High negative reward for incorrectly allowing a labeled Attack.
    - Small negative reward (cost) for incorrectly blocking Benign traffic.

### 1.4. Train Baseline Models
- **Action:** Use the existing `BenchmarkRunner` to train and evaluate the RL agents (DQN, PPO, A2C) only on the CICIoT2023 dataset.
- **Outcome:** A set of baseline performance metrics. This will be the benchmark against which you will compare your hybrid data models.

## Phase 2: Synthetic Data Generation (GAN)
This phase focuses on creating the synthetic data generator to address the limitations of the real dataset.

### 2.1. GAN Model Implementation
- **Action:** Design and implement a GAN.
- **Task:** Create a new script (e.g., `src/models/gan_generator.py`). A Conditional GAN (cGAN) is a good choice to generate data for specific attack types.

### 2.2. Training the GAN
- **Action:** Train the GAN on the real attack data from CICIoT2023.
- **Task:** The goal is for the GAN's generator to learn the underlying distribution of the real attacks.

### 2.3. Generating the Synthetic Dataset
- **Action:** Use the trained generator to produce a new, synthetic dataset.
- **Task:** Create a balanced dataset by generating more samples for the rare attack categories.

## Phase 3: Hybrid Model Training & Thesis Experiments
This is the core research phase where you integrate both data sources to create the final, adaptive system.

### 3.1. Design and Run Integration Experiments
- **Action:** Use the `BenchmarkRunner` to conduct a new set of experiments comparing different data integration strategies.
- **Task:** Implement and compare the performance of models trained with:
    - **Strategy A (Pre-training/Fine-tuning):** Train the RL agents on the large synthetic dataset first, then fine-tune the policy using the real dataset.
    - **Strategy B (Data Mixing):** Train the RL agents on a hybrid dataset composed of both real and synthetic samples.

### 3.2. Analyze and Document Results
- **Action:** Compare the performance of the hybrid models against the baseline models.
- **Task:** Your analysis should prove that integrated data leads to a more robust defense system, especially for detecting rare attack types.